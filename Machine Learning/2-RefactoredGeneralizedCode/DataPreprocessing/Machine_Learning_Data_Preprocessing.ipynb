{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "UAUFt1MXUZRN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "755-xUBoy6oQ"
      },
      "outputs": [],
      "source": [
        "#Data Preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "import shutil\n",
        "from io import StringIO\n",
        "\n",
        "def get_dataset(datasets):\n",
        "    os.environ['KAGGLE_USERNAME'] = 'mohamedadel452'\n",
        "    os.environ['KAGGLE_KEY'] = 'a6ea873bc8a4c8196d2683d147696840'\n",
        "    for dataset in datasets:\n",
        "        !kaggle datasets download -d {dataset}\n",
        "        with zipfile.ZipFile('/content/' + dataset.split('/')[1] + '.zip', 'r') as zip_ref:\n",
        "            zip_ref.extractall('/content/' + dataset.split('/')[1])\n",
        "\n",
        "def random_percent(data_dictionary, percent):\n",
        "    data = {}\n",
        "    for chunk in data_dictionary.items():\n",
        "        chunk_name = chunk[0]\n",
        "        chunk_data = chunk[1]\n",
        "        random.seed(42)\n",
        "        random.shuffle(chunk_data)\n",
        "        data[chunk_name] = chunk_data[:int(len(chunk_data) * percent)]\n",
        "    return data\n",
        "\n",
        "def check_keyword(string, list_of_strings):\n",
        "    if any(keyword in string for keyword in list_of_strings):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def split_data(data, percent = None):\n",
        "    train_data, validation_data, test_data = [], [], []\n",
        "\n",
        "    if percent:\n",
        "        random.seed(42)\n",
        "        random.shuffle(data)\n",
        "\n",
        "        val_size = int(len(data['all_data']) * percent)\n",
        "        test_size = int(len(data['all_data']) * percent)\n",
        "\n",
        "        validation_data = data['all_data'][:val_size]\n",
        "        test_data = data['all_data'][val_size:(val_size + test_size)]\n",
        "        train_data = data['all_data'][(val_size + test_size):]\n",
        "\n",
        "    else:\n",
        "        if not any(keyword in data['all_data'][0][0] for keyword in ['train', 'validation', 'val', 'test']):\n",
        "            print('Please enter split percentage.')\n",
        "            return data\n",
        "        else:\n",
        "            for image_path, label in data['all_data']:\n",
        "                if check_keyword(image_path, ['train']):\n",
        "                    train_data.append((image_path, label))\n",
        "                if check_keyword(image_path, ['validation', 'val']):\n",
        "                    validation_data.append((image_path, label))\n",
        "                if check_keyword(image_path, ['test']):\n",
        "                    test_data.append((image_path, label))\n",
        "\n",
        "    data = {'train_data': train_data,'validation_data': validation_data,'test_data': test_data}\n",
        "    print(len(data['train_data']))\n",
        "    print(len(data['validation_data']))\n",
        "    print(len(data['test_data']))\n",
        "    return data\n",
        "\n",
        "def load_data(meta_data, lodaing_type):\n",
        "    if 'image_directory' in meta_data:\n",
        "        image_directory  = meta_data['image_directory']\n",
        "    if 'labels_directory' in meta_data:\n",
        "           labels_directory = meta_data['labels_directory']\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    if loading_type == \"csv_labels_one_hot_encoding\":\n",
        "      for each in labels_directory:\n",
        "        labels_df = pd.read_csv(each)\n",
        "        each_labels = np.argmax(labels_df.drop(columns=['image']).values, axis=1)\n",
        "        image_names = labels_df['image'].values\n",
        "        for name in image_names:\n",
        "          for each in image_directory:\n",
        "            if os.path.exists(each + '/' + name + \".jpg\"):\n",
        "              image_paths.append(each + '/' + name + \".jpg\")\n",
        "              break\n",
        "            if os.path.exists(each + '/' + name + \".png\"):\n",
        "              image_paths.append(each + '/' + name + \".png\")\n",
        "              break\n",
        "        labels += list(each_labels)\n",
        "\n",
        "    if loading_type == \"images_in_folder_labels\":\n",
        "        for each in image_directory:\n",
        "          for root, dirs, files in os.walk(each):\n",
        "              for file in files:\n",
        "                  image_paths.append(os.path.join(root, file))\n",
        "                  labels.append(root.split('/')[-1])\n",
        "\n",
        "    if 'new_class' in meta_data:\n",
        "        labels = [meta_data['new_class'] for _ in range(len(labels))]\n",
        "\n",
        "    data = {'all_data': list(zip(image_paths, labels))}\n",
        "    print(len(data['all_data']))\n",
        "    return data\n",
        "\n",
        "def oversample(data_dictionary):\n",
        "    data = {}\n",
        "    for chunk in data_dictionary.items():\n",
        "        chunk_name = chunk[0]\n",
        "        chunk_data = chunk[1]\n",
        "        image_paths, labels = map(lambda x: list(x), zip(*chunk_data))\n",
        "        if len(set(labels)) != 1:\n",
        "            oversampler = RandomOverSampler(random_state = 3)\n",
        "            image_paths, labels  = oversampler.fit_resample(np.array(image_paths).reshape(-1, 1), labels)\n",
        "            image_paths = [str(image_path[0]) for image_path in image_paths]\n",
        "\n",
        "        data[chunk_name] = list(zip(image_paths, labels))\n",
        "    return data\n",
        "\n",
        "def resize_and_save(input_path, output_path, new_size):\n",
        "    original_image = Image.open(input_path)\n",
        "    resized_image = original_image.resize(new_size)\n",
        "    rgb_image = resized_image.convert(\"RGB\")\n",
        "    rgb_image.save(output_path, 'JPEG')\n",
        "\n",
        "\n",
        "def transform_data(data, classes, output_directory, oversample_bool = 0, new_size = (128,128)):\n",
        "    if oversample_bool == 1:\n",
        "\n",
        "      temp_output_directory = '/content/temp'\n",
        "      if not os.path.exists(temp_output_directory):\n",
        "        os.makedirs(temp_output_directory)\n",
        "      old_stdout = sys.stdout\n",
        "      sys.stdout = StringIO()\n",
        "      transform_data(data, classes, temp_output_directory, 0, new_size = (128,128))\n",
        "      sys.stdout = old_stdout\n",
        "      data = load_data({'image_directory': [temp_output_directory]}, 'images_in_folder_labels')\n",
        "      data = split_data(data)\n",
        "      print(len(data['train_data']))\n",
        "      data = oversample(data)\n",
        "      print(len(data['train_data']))\n",
        "      print(data['train_data'][0][0])\n",
        "      class_vals = list(classes.values())\n",
        "      classes = dict(zip([str(c) for c in class_vals], class_vals))\n",
        "      data = transform_data(data, classes, output_directory)\n",
        "      shutil.rmtree(temp_output_directory)\n",
        "    else:\n",
        "      for chunk in data.items():\n",
        "          chunk_name = chunk[0]\n",
        "          chunk_data = chunk[1]\n",
        "          print(f\"\\n\\nProcessing {chunk_name} Started..\")\n",
        "          i = 0\n",
        "          for image_path, label in chunk_data:\n",
        "              image_name = image_path.split('/')[-1].split('.')[0] + str(i) + '.' +image_path.split('/')[-1].split('.')[1]\n",
        "              class_num =str(classes[str(label)])\n",
        "              class_output_dir = os.path.join(output_directory, chunk_name, class_num)\n",
        "              if not os.path.exists(class_output_dir):\n",
        "                  os.makedirs(class_output_dir)\n",
        "              output_image_path = os.path.join(class_output_dir, image_name)\n",
        "              resize_and_save(image_path, output_image_path, new_size)\n",
        "              i += 1\n",
        "              if (i + 1) % (len(chunk_data) // 10) == 0:\n",
        "                  print(\"Progress: \" + str(i) + '/' + str(len(chunk_data)) + \" \"+ str(round(i /len(chunk_data) * 100))+ \"%\")\n",
        "    print(\"\\n\\nProcessing has finished.\")\n",
        "    print(\"\\n Data was saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XKfVYy7iW9QK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model-1"
      ],
      "metadata": {
        "id": "Dsp_loL0Lxzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model_1\n",
        "datasets = ['surajghuwalewala/ham1000-segmentation-and-classification', 'nazmussadat013/fitz17k-dataset', 'lijiyu/imagenet']\n",
        "image_directory = ['/content/ham1000-segmentation-and-classification/images', 'fitz17k-dataset/data/finalfitz17k', 'imagenet/imagenet']\n",
        "\n",
        "output_directory = '/content/output_1'\n",
        "classes = {'0':0, '1':1}\n",
        "new_class_0 = \"0\"\n",
        "new_class_1 = \"1\"\n",
        "\n",
        "#HAM10000\n",
        "meta_data = {'image_directory': [image_directory[0]]}\n",
        "meta_data['new_class'] = new_class_1\n",
        "meta_data['labels_directory'] = ['/content/ham1000-segmentation-and-classification/GroundTruth.csv']\n",
        "loading_type = \"csv_labels_one_hot_encoding\"\n",
        "\n",
        "get_dataset(datasets)\n",
        "data_1 = load_data(meta_data, loading_type)\n",
        "\n",
        "#Fitz17k\n",
        "meta_data = {'image_directory': [image_directory[1]]}\n",
        "meta_data['new_class'] = new_class_1\n",
        "loading_type = \"images_in_folder_labels\"\n",
        "\n",
        "data_2 = load_data(meta_data, loading_type)\n",
        "\n",
        "#imageNet\n",
        "meta_data = {'image_directory': [image_directory[2]]}\n",
        "meta_data['new_class'] = new_class_0\n",
        "loading_type = \"images_in_folder_labels\"\n",
        "\n",
        "data_3 = load_data(meta_data, loading_type)\n",
        "\n",
        "data = {}\n",
        "for key in data_1:\n",
        "    data[key] = data_1[key] + data_2[key] + data_3[key]\n",
        "\n",
        "data = split_data(data, .10)\n",
        "data = oversample(data)\n",
        "data = transform_data(data, classes, output_directory)\n",
        "shutil.make_archive('output_1', 'zip', '/content/output_1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EYJc49i0L26C",
        "outputId": "a697d72f-756b-471a-ce62-8cfdc0a3219b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/surajghuwalewala/ham1000-segmentation-and-classification\n",
            "License(s): Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)\n",
            "ham1000-segmentation-and-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Dataset URL: https://www.kaggle.com/datasets/nazmussadat013/fitz17k-dataset\n",
            "License(s): Apache 2.0\n",
            "fitz17k-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Dataset URL: https://www.kaggle.com/datasets/lijiyu/imagenet\n",
            "License(s): unknown\n",
            "imagenet.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "10015\n",
            "16577\n",
            "50000\n",
            "61274\n",
            "7659\n",
            "7659\n",
            "\n",
            "\n",
            "Processing train_data Started..\n",
            "Progress: 9999/100000 10%\n",
            "Progress: 19999/100000 20%\n",
            "Progress: 29999/100000 30%\n",
            "Progress: 39999/100000 40%\n",
            "Progress: 49999/100000 50%\n",
            "Progress: 59999/100000 60%\n",
            "Progress: 69999/100000 70%\n",
            "Progress: 79999/100000 80%\n",
            "Progress: 89999/100000 90%\n",
            "Progress: 99999/100000 100%\n",
            "\n",
            "\n",
            "Processing validation_data Started..\n",
            "Progress: 764/7659 10%\n",
            "Progress: 1529/7659 20%\n",
            "Progress: 2294/7659 30%\n",
            "Progress: 3059/7659 40%\n",
            "Progress: 3824/7659 50%\n",
            "Progress: 4589/7659 60%\n",
            "Progress: 5354/7659 70%\n",
            "Progress: 6119/7659 80%\n",
            "Progress: 6884/7659 90%\n",
            "Progress: 7649/7659 100%\n",
            "\n",
            "\n",
            "Processing test_data Started..\n",
            "Progress: 764/7659 10%\n",
            "Progress: 1529/7659 20%\n",
            "Progress: 2294/7659 30%\n",
            "Progress: 3059/7659 40%\n",
            "Progress: 3824/7659 50%\n",
            "Progress: 4589/7659 60%\n",
            "Progress: 5354/7659 70%\n",
            "Progress: 6119/7659 80%\n",
            "Progress: 6884/7659 90%\n",
            "Progress: 7649/7659 100%\n",
            "\n",
            "\n",
            "Processing has finished.\n",
            "\n",
            " Data was saved.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/output_1.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model-2"
      ],
      "metadata": {
        "id": "Bd5nGnUVLcEM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMHRn5KQzVVj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "outputId": "aac89f4d-a38d-42d2-a616-116c88291a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/surajghuwalewala/ham1000-segmentation-and-classification\n",
            "License(s): Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)\n",
            "ham1000-segmentation-and-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "10015\n",
            "8013\n",
            "1001\n",
            "1001\n",
            "\n",
            "\n",
            "Processing train_data Started..\n",
            "Progress: 3731/37324 10%\n",
            "Progress: 7463/37324 20%\n",
            "Progress: 11195/37324 30%\n",
            "Progress: 14927/37324 40%\n",
            "Progress: 18659/37324 50%\n",
            "Progress: 22391/37324 60%\n",
            "Progress: 26123/37324 70%\n",
            "Progress: 29855/37324 80%\n",
            "Progress: 33587/37324 90%\n",
            "Progress: 37319/37324 100%\n",
            "\n",
            "\n",
            "Processing validation_data Started..\n",
            "Progress: 479/4802 10%\n",
            "Progress: 959/4802 20%\n",
            "Progress: 1439/4802 30%\n",
            "Progress: 1919/4802 40%\n",
            "Progress: 2399/4802 50%\n",
            "Progress: 2879/4802 60%\n",
            "Progress: 3359/4802 70%\n",
            "Progress: 3839/4802 80%\n",
            "Progress: 4319/4802 90%\n",
            "Progress: 4799/4802 100%\n",
            "\n",
            "\n",
            "Processing test_data Started..\n",
            "Progress: 479/4809 10%\n",
            "Progress: 959/4809 20%\n",
            "Progress: 1439/4809 30%\n",
            "Progress: 1919/4809 40%\n",
            "Progress: 2399/4809 50%\n",
            "Progress: 2879/4809 60%\n",
            "Progress: 3359/4809 70%\n",
            "Progress: 3839/4809 80%\n",
            "Progress: 4319/4809 90%\n",
            "Progress: 4799/4809 100%\n",
            "\n",
            "\n",
            "Processing has finished.\n",
            "\n",
            " Data was saved.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/output_4.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "#Model_2\n",
        "datasets = ['surajghuwalewala/ham1000-segmentation-and-classification']\n",
        "image_directory = ['/content/ham1000-segmentation-and-classification/images']\n",
        "output_directory = '/content/output_2'\n",
        "classes = {'0':0, '1':1, '2':2, '3':3, '4':4, '5':5, '6':6}\n",
        "meta_data = {'image_directory': image_directory}\n",
        "meta_data['labels_directory'] = ['/content/ham1000-segmentation-and-classification/GroundTruth.csv']\n",
        "loading_type = \"csv_labels_one_hot_encoding\"\n",
        "\n",
        "get_dataset(datasets)\n",
        "data = load_data(meta_data, loading_type)\n",
        "data = split_data(data, .10)\n",
        "data = oversample(data)\n",
        "data = transform_data(data, classes, output_directory)\n",
        "shutil.make_archive('output_2', 'zip', '/content/output_2')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model-3"
      ],
      "metadata": {
        "id": "w0cBLlC3LnZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model_3\n",
        "datasets = ['shaheedanwarfahad/augmentation-task-pad-ufes-20']\n",
        "image_directory = ['/content/augmentation-task-pad-ufes-20/PAD/Posterior_Augmentation']\n",
        "output_directory = '/content/output_3'\n",
        "classes = {'MEL': 0, 'NEV':1,'BCC':2,'ACK': 3,'SCC': 4,'SEK':5}\n",
        "meta_data = {'image_directory': image_directory}\n",
        "loading_type = \"images_in_folder_labels\"\n",
        "\n",
        "get_dataset(datasets)\n",
        "data = load_data(meta_data, loading_type)\n",
        "data = split_data(data)\n",
        "data = oversample(data)\n",
        "data = transform_data(data, classes, output_directory)\n",
        "shutil.make_archive('output_3', 'zip', '/content/output_3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "hVpRMGVCxvlz",
        "outputId": "6b213694-b1bf-48d1-9b83-4a71a82f6cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/shaheedanwarfahad/augmentation-task-pad-ufes-20\n",
            "License(s): unknown\n",
            "augmentation-task-pad-ufes-20.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "62916\n",
            "46369\n",
            "12335\n",
            "4212\n",
            "\n",
            "\n",
            "Processing train_data Started..\n",
            "Progress: 4799/48000 10%\n",
            "Progress: 9599/48000 20%\n",
            "Progress: 14399/48000 30%\n",
            "Progress: 19199/48000 40%\n",
            "Progress: 23999/48000 50%\n",
            "Progress: 28799/48000 60%\n",
            "Progress: 33599/48000 70%\n",
            "Progress: 38399/48000 80%\n",
            "Progress: 43199/48000 90%\n",
            "Progress: 47999/48000 100%\n",
            "\n",
            "\n",
            "Processing validation_data Started..\n",
            "Progress: 1781/17826 10%\n",
            "Progress: 3563/17826 20%\n",
            "Progress: 5345/17826 30%\n",
            "Progress: 7127/17826 40%\n",
            "Progress: 8909/17826 50%\n",
            "Progress: 10691/17826 60%\n",
            "Progress: 12473/17826 70%\n",
            "Progress: 14255/17826 80%\n",
            "Progress: 16037/17826 90%\n",
            "Progress: 17819/17826 100%\n",
            "\n",
            "\n",
            "Processing test_data Started..\n",
            "Progress: 603/6048 10%\n",
            "Progress: 1207/6048 20%\n",
            "Progress: 1811/6048 30%\n",
            "Progress: 2415/6048 40%\n",
            "Progress: 3019/6048 50%\n",
            "Progress: 3623/6048 60%\n",
            "Progress: 4227/6048 70%\n",
            "Progress: 4831/6048 80%\n",
            "Progress: 5435/6048 90%\n",
            "Progress: 6039/6048 100%\n",
            "\n",
            "\n",
            "Processing has finished.\n",
            "\n",
            " Data was saved.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/output_3.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4"
      ],
      "metadata": {
        "id": "3KC-ZrzNLjg5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "lLSCg8jBy6oR",
        "outputId": "0dbac211-bd8f-42d6-823e-db1ca5f06f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohamedadel452/model-4-data-ham10000-pad-google-images-camera\n",
            "License(s): unknown\n",
            "model-4-data-ham10000-pad-google-images-camera.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "83954\n",
            "167750\n",
            "/content/temp/train_data/0/240_F_100032446_oArfjQ27b5sUTPSLKfdng3ABoIspiERM55.jpg\n",
            "\n",
            "\n",
            "Processing train_data Started..\n",
            "Progress: 16774/167750 10%\n",
            "Progress: 33549/167750 20%\n",
            "Progress: 50324/167750 30%\n",
            "Progress: 67099/167750 40%\n",
            "Progress: 83874/167750 50%\n",
            "Progress: 100649/167750 60%\n",
            "Progress: 117424/167750 70%\n",
            "Progress: 134199/167750 80%\n",
            "Progress: 150974/167750 90%\n",
            "Progress: 167749/167750 100%\n",
            "\n",
            "\n",
            "Processing validation_data Started..\n",
            "Progress: 1705/17060 10%\n",
            "Progress: 3411/17060 20%\n",
            "Progress: 5117/17060 30%\n",
            "Progress: 6823/17060 40%\n",
            "Progress: 8529/17060 50%\n",
            "Progress: 10235/17060 60%\n",
            "Progress: 11941/17060 70%\n",
            "Progress: 13647/17060 80%\n",
            "Progress: 15353/17060 90%\n",
            "Progress: 17059/17060 100%\n",
            "\n",
            "\n",
            "Processing test_data Started..\n",
            "Progress: 890/8916 10%\n",
            "Progress: 1781/8916 20%\n",
            "Progress: 2672/8916 30%\n",
            "Progress: 3563/8916 40%\n",
            "Progress: 4454/8916 50%\n",
            "Progress: 5345/8916 60%\n",
            "Progress: 6236/8916 70%\n",
            "Progress: 7127/8916 80%\n",
            "Progress: 8018/8916 90%\n",
            "Progress: 8909/8916 100%\n",
            "\n",
            "\n",
            "Processing has finished.\n",
            "\n",
            " Data was saved.\n",
            "\n",
            "\n",
            "Processing has finished.\n",
            "\n",
            " Data was saved.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/output_4.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Model_4\n",
        "datasets = ['mohamedadel452/model-4-data-ham10000-pad-google-images-camera']\n",
        "image_directory = ['/content/model-4-data-ham10000-pad-google-images-camera']\n",
        "output_directory = '/content/output_4'\n",
        "classes = {str(l): n for l, n in zip(range(6), range(6))}\n",
        "meta_data = {'image_directory': image_directory}\n",
        "loading_type = \"images_in_folder_labels\"\n",
        "\n",
        "get_dataset(datasets)\n",
        "data = load_data(meta_data, loading_type)\n",
        "data = split_data(data)\n",
        "data = transform_data(data, classes, output_directory, oversample_bool = 1)\n",
        "shutil.make_archive('output_4', 'zip', '/content/output_4')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 5259015,
          "sourceId": 8754662,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30732,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}